import cv2
import numpy as np
import pyrealsense2 as rs
import os
from collections import deque

SAVE_FILE = "camcalib.npz"

# ë§ˆì»¤ ì¤‘ì‹¬ ì›”ë“œ ì¢Œí‘œ (cm), í…Œì´ë¸” í‰ë©´ Z=0
WORLD_MARKER_CENTER = {
    0: np.array([0.0, 0.0, 0.0], dtype=np.float32),
    1: np.array([0.0, 40.0, 0.0], dtype=np.float32),
    2: np.array([36.0, 0.0, 0.0], dtype=np.float32),
    3: np.array([36.0, 40.0, 0.0], dtype=np.float32),
}

MARKER_SIZE_CM = 9.3  # <<<< ë°˜ë“œì‹œ ì‹¤ì¸¡í•´ì„œ ì •í™•íˆ!
MIN_MARKERS_PER_FRAME = 2   # í”„ë ˆì„ë‹¹ ìµœì†Œ ë§ˆì»¤ ìˆ˜ (ì½”ë„ˆ=8ì  ì´ìƒ í™•ë³´)
ACCUM_FRAMES = 60           # ëˆ„ì  í”„ë ˆì„ ìˆ˜
REPROJ_OK_MEAN_PX = 2.0     # í‰ê·  ì¬íˆ¬ì˜ ì˜¤ì°¨ í—ˆìš© ê¸°ì¤€(ì°¸ê³ )

def make_marker_corners_world(center_xyz_cm, marker_size_cm):
    """centerë¥¼ ê¸°ì¤€ìœ¼ë¡œ 4 ì½”ë„ˆì˜ ì›”ë“œ 3D ì¢Œí‘œ ìƒì„± (Z=0)"""
    s = marker_size_cm
    half = s / 2.0
    # OpenCV ArUco ì½”ë„ˆ ìˆœì„œ: TL, TR, BR, BL
    offsets = np.array([
        [-half, -half, 0.0],  # TL
        [ half, -half, 0.0],  # TR
        [ half,  half, 0.0],  # BR
        [-half,  half, 0.0],  # BL
    ], dtype=np.float32)
    return center_xyz_cm.reshape(1, 3) + offsets

def reprojection_error(obj_pts, img_pts, rvec, tvec, K, dist):
    proj, _ = cv2.projectPoints(obj_pts, rvec, tvec, K, dist)
    proj = proj.reshape(-1, 2)
    err = np.linalg.norm(proj - img_pts, axis=1)
    return float(err.mean()), float(err.max())

class RealsenseCalibratorAccurate:
    def __init__(self):
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
        config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)
        self.profile = self.pipeline.start(config)
        self.align = rs.align(rs.stream.color)

        intr = self.profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()
        self.camera_matrix = np.array([[intr.fx, 0, intr.ppx],
                                       [0, intr.fy, intr.ppy],
                                       [0, 0, 1]], dtype=np.float32)
        self.dist_coeffs = np.array(intr.coeffs, dtype=np.float32)

        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        self.aruco_params = cv2.aruco.DetectorParameters()

        self.T_cam_to_work = None
        self.load_calibration()

        # ëˆ„ì  ë²„í¼
        self.acc_obj = deque(maxlen=ACCUM_FRAMES)
        self.acc_img = deque(maxlen=ACCUM_FRAMES)

    def load_calibration(self):
        if os.path.exists(SAVE_FILE):
            data = np.load(SAVE_FILE)
            self.T_cam_to_work = data["T_cam_to_work"]
            if "camera_matrix" in data and "dist_coeffs" in data:
                self.camera_matrix = data["camera_matrix"]
                self.dist_coeffs = data["dist_coeffs"]
            print(f"âœ… ê¸°ì¡´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë¡œë“œ: {SAVE_FILE}")
        else:
            print("âš ï¸ ì €ì¥ëœ ì„¤ì • ì—†ìŒ. 'Space'ë¥¼ ëˆŒëŸ¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜")

    def accumulate_points(self, corners, ids):
        """í˜„ì¬ í”„ë ˆì„ì—ì„œ ì½”ë„ˆë“¤ì„ ì›”ë“œ/ì´ë¯¸ì§€ ëŒ€ì‘ì ìœ¼ë¡œ ë³€í™˜í•´ ëˆ„ì """
        if ids is None:
            return 0, 0

        ids = ids.flatten()
        obj_pts_list = []
        img_pts_list = []
        used_markers = 0

        for i, mid in enumerate(ids):
            if mid not in WORLD_MARKER_CENTER:
                continue
            # ì´ë¯¸ì§€ ì½”ë„ˆ 4ê°œ (TL,TR,BR,BL), shape (4,2)
            img_c = corners[i][0].astype(np.float32)
            # ì›”ë“œ ì½”ë„ˆ 4ê°œ (cm)
            obj_c = make_marker_corners_world(WORLD_MARKER_CENTER[mid], MARKER_SIZE_CM)

            obj_pts_list.append(obj_c)
            img_pts_list.append(img_c)
            used_markers += 1

        if used_markers >= MIN_MARKERS_PER_FRAME:
            obj_pts = np.concatenate(obj_pts_list, axis=0)  # (4*M,3)
            img_pts = np.concatenate(img_pts_list, axis=0)  # (4*M,2)
            self.acc_obj.append(obj_pts)
            self.acc_img.append(img_pts)

        return used_markers, len(self.acc_obj)

    def solve_from_accumulated(self):
        """ëˆ„ì ëœ ëŒ€ì‘ì ìœ¼ë¡œ RANSAC+Refineë¡œ ìµœì¢… ìì„¸ ì¶”ì •"""
        if len(self.acc_obj) < max(10, ACCUM_FRAMES // 3):
            print(f"âŒ ëˆ„ì  í”„ë ˆì„ ë¶€ì¡±: {len(self.acc_obj)}")
            return False

        obj_pts = np.concatenate(list(self.acc_obj), axis=0).astype(np.float32)
        img_pts = np.concatenate(list(self.acc_img), axis=0).astype(np.float32)

        # 1) RANSACë¡œ ì´ˆê¸° (ì•„ì›ƒë¼ì´ì–´ ì œê±°)
        ok, rvec, tvec, inliers = cv2.solvePnPRansac(
            obj_pts, img_pts, self.camera_matrix, self.dist_coeffs,
            iterationsCount=200,
            reprojectionError=3.0,   # px, ìƒí™©ì— ë”°ë¼ 2~5 ì¡°ì •
            confidence=0.999,
            flags=cv2.SOLVEPNP_ITERATIVE
        )
        if not ok or inliers is None or len(inliers) < 20:
            print("âŒ solvePnPRansac ì‹¤íŒ¨ ë˜ëŠ” inlier ë¶€ì¡±")
            return False

        in_obj = obj_pts[inliers.flatten()]
        in_img = img_pts[inliers.flatten()]

        # 2) LM refineë¡œ ì •ë°€í™” (OpenCV 4.1+)
        try:
            rvec, tvec = cv2.solvePnPRefineLM(
                in_obj, in_img, self.camera_matrix, self.dist_coeffs, rvec, tvec
            )
        except Exception:
            # ë²„ì „ì— ë”°ë¼ Refineê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë‹ˆ fallback
            pass

        mean_px, max_px = reprojection_error(in_obj, in_img, rvec, tvec, self.camera_matrix, self.dist_coeffs)

        # ë³€í™˜í–‰ë ¬ êµ¬ì„± (ì›”ë“œ->ì¹´ë©”ë¼)
        R, _ = cv2.Rodrigues(rvec)
        T_w2c = np.eye(4, dtype=np.float32)
        T_w2c[:3, :3] = R.astype(np.float32)
        T_w2c[:3, 3] = tvec.flatten().astype(np.float32)

        self.T_cam_to_work = np.linalg.inv(T_w2c).astype(np.float32)

        np.savez(
            SAVE_FILE,
            T_cam_to_work=self.T_cam_to_work,
            camera_matrix=self.camera_matrix,
            dist_coeffs=self.dist_coeffs,
            marker_size_cm=np.float32(MARKER_SIZE_CM),
            reproj_mean_px=np.float32(mean_px),
            reproj_max_px=np.float32(max_px),
            inliers=np.int32(len(inliers)),
            total_points=np.int32(len(obj_pts)),
        )

        print("âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ")
        print(f"   - ëˆ„ì  í”„ë ˆì„: {len(self.acc_obj)}")
        print(f"   - ì´ ì : {len(obj_pts)}, inlier: {len(inliers)}")
        print(f"   - ì¬íˆ¬ì˜ ì˜¤ì°¨(mean/max): {mean_px:.2f}px / {max_px:.2f}px")
        print(f"   - ì €ì¥: {SAVE_FILE}")

        if mean_px > REPROJ_OK_MEAN_PX:
            print("âš ï¸ í‰ê·  ì¬íˆ¬ì˜ ì˜¤ì°¨ê°€ í° í¸ì…ë‹ˆë‹¤. (ë§ˆì»¤ ì¸ì‡„/ì‹¤ì¸¡/ì¡°ëª…/í”ë“¤ë¦¼/ì™œê³¡ê³„ìˆ˜) ì ê²€ ê¶Œì¥.")

        return True

    def run(self):
        cv2.namedWindow("Calibration View")
        print("\n[ì‘ë™ë²•]")
        print("- SPACE: ëˆ„ì ëœ í”„ë ˆì„ìœ¼ë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰ ë° ì €ì¥")
        print("- R: ëˆ„ì  ë²„í¼ ë¦¬ì…‹")
        print("- ESC: ì¢…ë£Œ\n")

        try:
            while True:
                frames = self.pipeline.wait_for_frames()
                aligned = self.align.process(frames)
                color_f = aligned.get_color_frame()
                if not color_f:
                    continue

                img = np.asanyarray(color_f.get_data())
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

                corners, ids, _ = cv2.aruco.detectMarkers(gray, self.aruco_dict, parameters=self.aruco_params)
                if ids is not None:
                    cv2.aruco.drawDetectedMarkers(img, corners, ids)

                used_markers, acc_n = self.accumulate_points(corners, ids)

                # ìƒíƒœ í‘œì‹œ
                cv2.putText(img, f"markers:{used_markers}  acc_frames:{acc_n}/{ACCUM_FRAMES}",
                            (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)

                key = cv2.waitKey(1) & 0xFF
                if key == ord(' '):
                    self.solve_from_accumulated()
                elif key == ord('r'):
                    self.acc_obj.clear()
                    self.acc_img.clear()
                    print("ğŸ§¹ ëˆ„ì  ë²„í¼ ë¦¬ì…‹")
                elif key == 27:
                    break

                cv2.imshow("Calibration View", img)

        finally:
            self.pipeline.stop()
            cv2.destroyAllWindows()

if __name__ == "__main__":
    app = RealsenseCalibratorAccurate()
    app.run()
